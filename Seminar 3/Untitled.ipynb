{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%wriefile Seminar3.py\n",
    "import os\n",
    "import torch\n",
    "import sys\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from torch.nn import MSELoss, Sequential, Linear, Sigmoid, Tanh\n",
    "from torch.autograd import Variable\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from torch import nn\n",
    "landmarks_frame = pd.read_csv('dataset/train/face_landmarks.csv')\n",
    "class FaceLandmarksDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.landmarks_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.landmarks_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.landmarks_frame.iloc[idx, 0])\n",
    "        image = io.imread(img_name)\n",
    "        landmarks = self.landmarks_frame.iloc[idx, 1:].as_matrix().astype('float')\n",
    "        landmarks = landmarks.reshape(-1, 2)\n",
    "        sample = {'image': image, 'landmarks': landmarks}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample['image'], sample['landmarks']\n",
    "\n",
    "        return {'image':  torch.from_numpy(image),\n",
    "                'landmarks': torch.from_numpy(landmarks)}\n",
    "class ToTensor2(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample['image'], sample['landmarks']\n",
    "\n",
    "        return {'image':  torch.from_numpy(image+np.random.randn(96*96).reshape(96, 96)*0.32),\n",
    "                'landmarks': torch.from_numpy(landmarks)}\n",
    "    \n",
    "train_dataset = FaceLandmarksDataset(csv_file='dataset/train/face_landmarks.csv',\n",
    "                                     root_dir='dataset/train',\n",
    "                                     transform=ToTensor2()\n",
    "                                     )\n",
    "\n",
    "test_dataset = FaceLandmarksDataset(csv_file='dataset/test/face_landmarks.csv',\n",
    "                                     root_dir='dataset/test',\n",
    "                                     transform=ToTensor()\n",
    "                                     )\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64,\n",
    "                        shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64,\n",
    "                        shuffle=True)\n",
    "\n",
    "dtype=torch.FloatTensor\n",
    "\n",
    "def train(network, epochs, learning_rate, loss=MSELoss(), optim=torch.optim.Adam):\n",
    "    train_loss_epochs = []\n",
    "    test_loss_epochs = []\n",
    "    optimizer = optim(network.parameters(), lr=learning_rate)\n",
    "    try:\n",
    "        for epoch in range(epochs):\n",
    "            losses = []\n",
    "            accuracies = []\n",
    "            for sample in train_dataloader:\n",
    "                X = sample['image']\n",
    "                X = X.view(X.shape[0],1,96,96).type(dtype)\n",
    "                #print(X.shape)\n",
    "                y = sample['landmarks']\n",
    "                y = y.view(y.shape[0], -1).type(dtype)\n",
    "                \n",
    "                prediction = network(X)\n",
    "                loss_batch = loss(prediction, y)\n",
    "                losses.append(loss_batch.item())\n",
    "                optimizer.zero_grad()\n",
    "                loss_batch.backward()\n",
    "                optimizer.step()\n",
    "  \n",
    "            train_loss_epochs.append(np.mean(losses))\n",
    "            losses = []    \n",
    "            for sample in test_dataloader:\n",
    "                X = sample['image']\n",
    "                X = X.view(X.shape[0],1,96,96).type(dtype)\n",
    "                #X = X.view(X.shape[0], -1).type(dtype)\n",
    "                y = sample['landmarks']\n",
    "                y = y.view(y.shape[0], -1).type(dtype)\n",
    "                \n",
    "                prediction = network(X)\n",
    "                loss_batch = loss(prediction, y)\n",
    "                losses.append(loss_batch.item())\n",
    "                \n",
    "            test_loss_epochs.append(np.mean(losses))\n",
    "            #sys.stdout.write('\\rEpoch {0}... (Train/Test) MSE: {1:.3f}/{2:.3f}'.format(\n",
    "              #          epoch, train_loss_epochs[-1], test_loss_epochs[-1]))\n",
    "            print(epoch, train_loss_epochs[-1], test_loss_epochs[-1])\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "image_size = 96\n",
    "def init_weights(layer):\n",
    "    if type(layer) == nn.Linear:\n",
    "        nn.init.xavier_normal(layer.weight)\n",
    "channels = 1\n",
    "class ConvClassifier(nn.Module):\n",
    "    def __init__(self, image_size):\n",
    "        super().__init__()\n",
    "        self.conv_layers = nn.Sequential(nn.Conv2d(channels, 8, (4,4), padding=(2,2)), nn.ReLU(),\n",
    "                                        nn.MaxPool2d(2),\n",
    "                                         nn.Conv2d(8, 16, (4,4), padding=(2,2)), nn.ReLU(),\n",
    "                                         nn.MaxPool2d(2),\n",
    "                                        nn.Conv2d(16, 32, (4,4), padding=(2,2)),nn.ReLU(),\n",
    "                                        nn.MaxPool2d(2),\n",
    "                                        nn.Conv2d(32, 64, (4,4), padding=1),nn.ReLU(),\n",
    "                                        nn.MaxPool2d(2))\n",
    "        self.linear_layers = nn.Sequential(nn.Linear(40*40, 400),\n",
    "                                           nn.BatchNorm1d(400),\n",
    "                                           nn.ReLU(),nn.Linear(400, 200),nn.ReLU(),\n",
    "                                           nn.BatchNorm1d(200),\n",
    "                                          nn.Linear(200, 2*68))\n",
    "        self.linear_layers.apply(init_weights)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear_layers(x)\n",
    "        #print(x.shape)\n",
    "        return x\n",
    "network = ConvClassifier(image_size=96)\n",
    "train(network, 750, 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
