{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating config object (argparse workaround)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    pass\n",
    "\n",
    "config = Config()\n",
    "config.mnist_path = None\n",
    "config.batch_size = 16\n",
    "config.num_workers = 3\n",
    "config.num_epochs = 10\n",
    "config.noise_size = 50\n",
    "config.print_freq = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataloder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torchvision.datasets.FashionMNIST(\"fashion_mnist\", train=True, transform=torchvision.transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(train, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3750"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, cat in dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 28, 28])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create generator and discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential( \n",
    "            nn.Linear(config.noise_size, 200),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(200, 28*28),\n",
    "            nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(28*28, 200),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(200, 50),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(50, 1), \n",
    "            nn.Sigmoid())\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create optimizers and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_G = optim.Adam(params=generator.parameters(), lr=0.0001)\n",
    "optim_D = optim.Adam(params=discriminator.parameters(), lr=0.0001)\n",
    "\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create necessary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Variable(torch.FloatTensor(config.batch_size, 28*28))\n",
    "noise = Variable(torch.FloatTensor(config.batch_size, config.noise_size))\n",
    "fixed_noise = Variable(torch.FloatTensor(config.batch_size, config.noise_size).normal_(0, 1))\n",
    "label = Variable(torch.FloatTensor(config.batch_size))\n",
    "real_label = 1\n",
    "fake_label = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание\n",
    "\n",
    "1) Посмотрите на реализацию GAN. Постройте интерполяцию между какими-нибудь двумя сгенерированными картинками. (Опционально)Добавьте свертки в генератор и дискриминатор, как в статье про DCGAN.\n",
    "\n",
    "2) Поменяйте ее, чтобы получился LSGAN https://arxiv.org/pdf/1611.04076v2.pdf\n",
    "\n",
    "3) Добавьте к обучению GAN условие на метку, продемонстрируйте условную генерацию. https://arxiv.org/pdf/1411.1784.pdf\n",
    "\n",
    "4) Напишите отчет что попробовали, какие результаты получили, как вам кажется надо обучать GAN, чтобы добиться сходимости?\n",
    "\n",
    "В каждом пункте постройте графики функций потерь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkrin\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:498: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1 Iter: 100 errD_x: 0.24 errD_z: 0.09 errG: 2.56\n",
      "Epoch:1 Iter: 200 errD_x: 0.11 errD_z: 0.08 errG: 2.82\n",
      "Epoch:1 Iter: 300 errD_x: 0.17 errD_z: 0.08 errG: 2.80\n",
      "Epoch:1 Iter: 400 errD_x: 0.57 errD_z: 0.09 errG: 2.61\n",
      "Epoch:1 Iter: 500 errD_x: 0.18 errD_z: 0.09 errG: 2.63\n",
      "Epoch:1 Iter: 600 errD_x: 0.07 errD_z: 0.04 errG: 3.27\n",
      "Epoch:1 Iter: 700 errD_x: 0.01 errD_z: 0.07 errG: 2.95\n",
      "Epoch:1 Iter: 800 errD_x: 0.06 errD_z: 0.06 errG: 3.12\n",
      "Epoch:1 Iter: 900 errD_x: 0.36 errD_z: 0.09 errG: 2.44\n",
      "Epoch:1 Iter: 1000 errD_x: 0.37 errD_z: 0.22 errG: 1.78\n",
      "Epoch:1 Iter: 1100 errD_x: 0.30 errD_z: 0.14 errG: 2.26\n",
      "Epoch:1 Iter: 1200 errD_x: 0.05 errD_z: 0.19 errG: 2.15\n",
      "Epoch:1 Iter: 1300 errD_x: 0.23 errD_z: 0.28 errG: 1.83\n",
      "Epoch:1 Iter: 1400 errD_x: 0.22 errD_z: 0.28 errG: 1.80\n",
      "Epoch:1 Iter: 1500 errD_x: 0.11 errD_z: 0.22 errG: 2.13\n",
      "Epoch:1 Iter: 1600 errD_x: 0.13 errD_z: 0.12 errG: 2.72\n",
      "Epoch:1 Iter: 1700 errD_x: 0.12 errD_z: 0.23 errG: 2.19\n",
      "Epoch:1 Iter: 1800 errD_x: 0.29 errD_z: 0.11 errG: 2.64\n",
      "Epoch:1 Iter: 1900 errD_x: 0.21 errD_z: 0.09 errG: 3.22\n",
      "Epoch:1 Iter: 2000 errD_x: 0.05 errD_z: 0.10 errG: 3.05\n",
      "Epoch:1 Iter: 2100 errD_x: 0.07 errD_z: 0.10 errG: 3.09\n",
      "Epoch:1 Iter: 2200 errD_x: 0.29 errD_z: 0.12 errG: 2.99\n",
      "Epoch:1 Iter: 2300 errD_x: 0.05 errD_z: 0.11 errG: 3.12\n",
      "Epoch:1 Iter: 2400 errD_x: 0.13 errD_z: 0.06 errG: 3.38\n",
      "Epoch:1 Iter: 2500 errD_x: 0.06 errD_z: 0.05 errG: 3.53\n",
      "Epoch:1 Iter: 2600 errD_x: 0.01 errD_z: 0.05 errG: 3.36\n",
      "Epoch:1 Iter: 2700 errD_x: 0.07 errD_z: 0.04 errG: 3.91\n",
      "Epoch:1 Iter: 2800 errD_x: 0.05 errD_z: 0.02 errG: 4.40\n",
      "Epoch:1 Iter: 2900 errD_x: 0.07 errD_z: 0.02 errG: 4.46\n",
      "Epoch:1 Iter: 3000 errD_x: 0.00 errD_z: 0.01 errG: 4.97\n",
      "Epoch:1 Iter: 3100 errD_x: 0.04 errD_z: 0.03 errG: 3.90\n",
      "Epoch:1 Iter: 3200 errD_x: 0.08 errD_z: 0.03 errG: 3.60\n",
      "Epoch:1 Iter: 3300 errD_x: 0.05 errD_z: 0.03 errG: 3.85\n",
      "Epoch:1 Iter: 3400 errD_x: 0.06 errD_z: 0.04 errG: 3.85\n",
      "Epoch:1 Iter: 3500 errD_x: 0.15 errD_z: 0.08 errG: 2.48\n",
      "Epoch:1 Iter: 3600 errD_x: 0.24 errD_z: 0.07 errG: 2.51\n",
      "Epoch:1 Iter: 3700 errD_x: 0.09 errD_z: 0.09 errG: 3.18\n",
      "Epoch:2 Iter: 100 errD_x: 0.07 errD_z: 0.10 errG: 2.55\n",
      "Epoch:2 Iter: 200 errD_x: 0.01 errD_z: 0.16 errG: 2.59\n",
      "Epoch:2 Iter: 300 errD_x: 0.09 errD_z: 0.11 errG: 2.76\n",
      "Epoch:2 Iter: 400 errD_x: 0.14 errD_z: 0.02 errG: 4.22\n",
      "Epoch:2 Iter: 500 errD_x: 0.15 errD_z: 0.13 errG: 2.71\n",
      "Epoch:2 Iter: 600 errD_x: 0.01 errD_z: 0.06 errG: 3.15\n",
      "Epoch:2 Iter: 700 errD_x: 0.46 errD_z: 0.02 errG: 3.89\n",
      "Epoch:2 Iter: 800 errD_x: 0.01 errD_z: 0.04 errG: 3.61\n",
      "Epoch:2 Iter: 900 errD_x: 0.01 errD_z: 0.11 errG: 3.32\n",
      "Epoch:2 Iter: 1000 errD_x: 0.21 errD_z: 0.08 errG: 2.94\n",
      "Epoch:2 Iter: 1100 errD_x: 0.09 errD_z: 0.07 errG: 2.98\n",
      "Epoch:2 Iter: 1200 errD_x: 0.06 errD_z: 0.03 errG: 3.81\n",
      "Epoch:2 Iter: 1300 errD_x: 0.02 errD_z: 0.06 errG: 3.69\n",
      "Epoch:2 Iter: 1400 errD_x: 0.00 errD_z: 0.05 errG: 3.70\n",
      "Epoch:2 Iter: 1500 errD_x: 0.19 errD_z: 0.05 errG: 3.78\n",
      "Epoch:2 Iter: 1600 errD_x: 0.22 errD_z: 0.13 errG: 2.89\n",
      "Epoch:2 Iter: 1700 errD_x: 0.00 errD_z: 0.13 errG: 3.05\n",
      "Epoch:2 Iter: 1800 errD_x: 0.26 errD_z: 0.12 errG: 2.42\n",
      "Epoch:2 Iter: 1900 errD_x: 0.10 errD_z: 0.06 errG: 3.09\n",
      "Epoch:2 Iter: 2000 errD_x: 0.11 errD_z: 0.06 errG: 3.83\n",
      "Epoch:2 Iter: 2100 errD_x: 0.44 errD_z: 0.07 errG: 2.77\n",
      "Epoch:2 Iter: 2200 errD_x: 0.03 errD_z: 0.50 errG: 1.96\n"
     ]
    }
   ],
   "source": [
    "ERRD_x = np.zeros(config.num_epochs)\n",
    "ERRD_z = np.zeros(config.num_epochs)\n",
    "ERRG = np.zeros(config.num_epochs)\n",
    "N = len(dataloader)\n",
    "\n",
    "for epoch in range(config.num_epochs):\n",
    "    for iteration, (images, cat) in enumerate(dataloader):\n",
    "        ####### \n",
    "        # Discriminator stage: maximize log(D(x)) + log(1 - D(G(z))) \n",
    "        #######\n",
    "        discriminator.zero_grad()\n",
    "        \n",
    "        # real\n",
    "        label.data.fill_(real_label)\n",
    "        input_data = images.view(images.shape[0], -1)\n",
    "        output = discriminator(input_data)\n",
    "        errD_x = criterion(output, label)\n",
    "        ERRD_x[epoch] += errD_x.item()\n",
    "        errD_x.backward()\n",
    "        \n",
    "        # fake \n",
    "        noise.data.normal_(0, 1)\n",
    "        fake = generator(noise)\n",
    "        label.data.fill_(fake_label)\n",
    "        output = discriminator(fake.detach())\n",
    "        errD_z = criterion(output, label)\n",
    "        ERRD_z[epoch] += errD_z.item()\n",
    "        errD_z.backward()\n",
    "        \n",
    "        optim_D.step()\n",
    "        \n",
    "        ####### \n",
    "        # Generator stage: maximize log(D(G(x))\n",
    "        #######\n",
    "        generator.zero_grad()\n",
    "        label.data.fill_(real_label)\n",
    "        output = discriminator(fake)\n",
    "        errG = criterion(output, label)\n",
    "        ERRG[epoch] += errG.item()\n",
    "        errG.backward()\n",
    "        \n",
    "        optim_G.step()\n",
    "        \n",
    "        if (iteration+1) % config.print_freq == 0:\n",
    "            print('Epoch:{} Iter: {} errD_x: {:.2f} errD_z: {:.2f} errG: {:.2f}'.format(epoch+1,\n",
    "                                                                                            iteration+1, \n",
    "                                                                                            errD_x.item(),\n",
    "                                                                                            errD_z.item(), \n",
    "                                                                                            errG.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noise.data.normal_(0, 1)\n",
    "fake = generator(noise)\n",
    "\n",
    "plt.figure(figsize=(6, 7))\n",
    "for i in range(16):\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(fake[i].detach().numpy().reshape(28, 28), cmap=plt.cm.Greys_r)\n",
    "    plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
